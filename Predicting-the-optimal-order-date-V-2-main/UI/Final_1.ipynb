{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c372730",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy scikit-learn xgboost tensorflow joblib matplotlib seaborn ipywidgets scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6d8337",
   "metadata": {},
   "source": [
    "# Training and Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57f1118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and scaler have been successfully saved in the 'models' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "import joblib\n",
    "\n",
    "# Ensure the 'models', 'img', and 'csv' directories exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('img', exist_ok=True)\n",
    "os.makedirs('csv', exist_ok=True)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('extended_inventory_dataset_35k.csv')\n",
    "\n",
    "# Add 'OrderID' column if it does not exist\n",
    "if 'OrderID' not in df.columns:\n",
    "    df['OrderID'] = df.index + 1\n",
    "\n",
    "# Convert date columns to datetime type\n",
    "df['OrderDate'] = pd.to_datetime(df['OrderDate'], errors='coerce')\n",
    "df['OptimalOrderDate'] = pd.to_datetime(df['OptimalOrderDate'], errors='coerce')\n",
    "df['ExpirationDate'] = pd.to_datetime(df['ExpirationDate'], errors='coerce')\n",
    "\n",
    "# Calculate the number of days until the optimal order date (target variable)\n",
    "df['DaysUntilOptimalOrder'] = (df['OptimalOrderDate'] - df['OrderDate']).dt.days\n",
    "\n",
    "# Remove NaN or negative values in 'DaysUntilOptimalOrder'\n",
    "df = df.dropna(subset=['DaysUntilOptimalOrder'])\n",
    "df = df[df['DaysUntilOptimalOrder'] > 0]\n",
    "\n",
    "# Define features and target variable\n",
    "features = ['LeadTime', 'StockOnHand', 'CapitalRecord', 'WeeklySales',\n",
    "            'OrderToReceiveTime', 'HoldingCost', 'DaysUntilExpiration']\n",
    "X = df[features]\n",
    "y = df['DaysUntilOptimalOrder']\n",
    "\n",
    "# Split the data into training and testing sets (70% training, 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 1. Train RandomForest Model\n",
    "rf_model = RandomForestRegressor(random_state=42, n_estimators=50, max_depth=4)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 2. Train XGBoost Model\n",
    "xgb_model = XGBRegressor(n_estimators=50, max_depth=3, learning_rate=0.1, subsample=0.8, random_state=42)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 3. Train Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Train Lasso Regression Model\n",
    "lasso_model = Lasso(alpha=0.1, max_iter=10000)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 5. Train Ridge Regression Model\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 6. Train Neural Network Model\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Input(shape=(X_train_scaled.shape[1],)))\n",
    "nn_model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "nn_model.add(Dropout(0.5))\n",
    "nn_model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "nn_model.add(Dropout(0.5))\n",
    "nn_model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "nn_model.add(Dense(1))\n",
    "nn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the Neural Network model\n",
    "nn_model.fit(X_train_scaled, y_train, epochs=200, batch_size=32, verbose=0)\n",
    "\n",
    "# Save the scaler and models\n",
    "joblib.dump(scaler, os.path.join('models', 'scaler.pkl'))\n",
    "joblib.dump(rf_model, os.path.join('models', 'rf_model.pkl'))\n",
    "joblib.dump(xgb_model, os.path.join('models', 'xgb_model.pkl'))\n",
    "joblib.dump(lr_model, os.path.join('models', 'lr_model.pkl'))\n",
    "joblib.dump(lasso_model, os.path.join('models', 'lasso_model.pkl'))\n",
    "joblib.dump(ridge_model, os.path.join('models', 'ridge_model.pkl'))\n",
    "nn_model.save(os.path.join('models', 'nn_model.h5'))  # Save model in HDF5 format\n",
    "\n",
    "print(\"Models and scaler have been successfully saved in the 'models' folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4071155",
   "metadata": {},
   "source": [
    "# Loading Models and Creating a User Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "312b3e6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1db227f5e3b40d68ff14f47b5e2a2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(GridBox(children=(Dropdown(description='Product:', options=('Cheese', 'Bananas', 'Cereal', 'Beeâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure the 'models', 'img', and 'csv' directories exist\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import scipy.stats as stats  # Ensure scipy is imported for Q-Q plots\n",
    "\n",
    "# Ensure inline plotting for Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the scaler and models\n",
    "scaler = joblib.load(os.path.join('models', 'scaler.pkl'))\n",
    "rf_model = joblib.load(os.path.join('models', 'rf_model.pkl'))\n",
    "xgb_model = joblib.load(os.path.join('models', 'xgb_model.pkl'))\n",
    "lr_model = joblib.load(os.path.join('models', 'lr_model.pkl'))\n",
    "lasso_model = joblib.load(os.path.join('models', 'lasso_model.pkl'))\n",
    "ridge_model = joblib.load(os.path.join('models', 'ridge_model.pkl'))\n",
    "nn_model = load_model(os.path.join('models', 'nn_model.h5'), compile=False)  # Load model without compiling\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('extended_inventory_dataset_35k.csv')\n",
    "\n",
    "# Add 'OrderID' column if it does not exist\n",
    "if 'OrderID' not in df.columns:\n",
    "    df['OrderID'] = df.index + 1\n",
    "\n",
    "# Convert date columns to datetime type\n",
    "df['OrderDate'] = pd.to_datetime(df['OrderDate'], errors='coerce')\n",
    "df['OptimalOrderDate'] = pd.to_datetime(df['OptimalOrderDate'], errors='coerce')\n",
    "df['ExpirationDate'] = pd.to_datetime(df['ExpirationDate'], errors='coerce')\n",
    "\n",
    "# Extract list of products (assuming 'Product' column exists)\n",
    "if 'Product' in df.columns:\n",
    "    product_list = df['Product'].unique()\n",
    "else:\n",
    "    print(\"Column 'Product' not found in the dataset.\")\n",
    "    raise ValueError(\"Column 'Product' not found in the dataset.\")\n",
    "\n",
    "# Calculate min and max for each numeric feature\n",
    "numeric_features = ['LeadTime', 'StockOnHand', 'CapitalRecord', 'WeeklySales',\n",
    "                    'OrderToReceiveTime', 'HoldingCost', 'DaysUntilExpiration']\n",
    "\n",
    "feature_mins = df[numeric_features].min()\n",
    "feature_maxs = df[numeric_features].max()\n",
    "\n",
    "# Define a common style for all widgets to adjust description width\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "# User Interface Widgets\n",
    "product_dropdown = widgets.Dropdown(\n",
    "    options=product_list,\n",
    "    description='Product:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "lead_time_slider = widgets.IntSlider(\n",
    "    min=int(feature_mins['LeadTime']),\n",
    "    max=int(feature_maxs['LeadTime']),\n",
    "    description='Lead Time:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "stock_on_hand_slider = widgets.IntSlider(\n",
    "    min=int(feature_mins['StockOnHand']),\n",
    "    max=int(feature_maxs['StockOnHand']),\n",
    "    description='Stock On Hand:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "capital_record_slider = widgets.FloatSlider(\n",
    "    min=float(feature_mins['CapitalRecord']),\n",
    "    max=float(feature_maxs['CapitalRecord']),\n",
    "    description='Capital Record:',\n",
    "    step=0.1,\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "weekly_sales_slider = widgets.IntSlider(\n",
    "    min=int(feature_mins['WeeklySales']),\n",
    "    max=int(feature_maxs['WeeklySales']),\n",
    "    description='Weekly Sales:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "order_to_receive_time_slider = widgets.IntSlider(\n",
    "    min=int(feature_mins['OrderToReceiveTime']),\n",
    "    max=int(feature_maxs['OrderToReceiveTime']),\n",
    "    description='Order to Receive Time:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "holding_cost_slider = widgets.FloatSlider(\n",
    "    min=float(feature_mins['HoldingCost']),\n",
    "    max=float(feature_maxs['HoldingCost']),\n",
    "    description='Holding Cost:',\n",
    "    step=0.1,\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "days_until_expiration_slider = widgets.IntSlider(\n",
    "    min=int(feature_mins['DaysUntilExpiration']),\n",
    "    max=int(feature_maxs['DaysUntilExpiration']),\n",
    "    description='Days Until Expiration:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "order_date_picker = widgets.DatePicker(\n",
    "    description='Order Date:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "predict_button = widgets.Button(\n",
    "    description='Predict',\n",
    "    button_style='success',\n",
    "    tooltip='Predict Optimal Order Date',\n",
    "    icon='check',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# Define function to update field values based on selected product\n",
    "def update_fields(change):\n",
    "    selected_product = product_dropdown.value\n",
    "    product_data = df[df['Product'] == selected_product].iloc[0]\n",
    "    lead_time_slider.value = int(product_data['LeadTime'])\n",
    "    stock_on_hand_slider.value = int(product_data['StockOnHand'])\n",
    "    capital_record_slider.value = float(product_data['CapitalRecord'])\n",
    "    weekly_sales_slider.value = int(product_data['WeeklySales'])\n",
    "    order_to_receive_time_slider.value = int(product_data['OrderToReceiveTime'])\n",
    "    holding_cost_slider.value = float(product_data['HoldingCost'])\n",
    "    days_until_expiration_slider.value = int(product_data['DaysUntilExpiration'])\n",
    "    order_date_picker.value = product_data['OrderDate'].date()\n",
    "\n",
    "# Connect product selection to the update function\n",
    "product_dropdown.observe(update_fields, names='value')\n",
    "\n",
    "# Initialize fields with the first product's data\n",
    "update_fields(None)\n",
    "\n",
    "# Define the prediction function\n",
    "def on_predict_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        # Collect input data\n",
    "        input_data = pd.DataFrame({\n",
    "            'LeadTime': [lead_time_slider.value],\n",
    "            'StockOnHand': [stock_on_hand_slider.value],\n",
    "            'CapitalRecord': [capital_record_slider.value],\n",
    "            'WeeklySales': [weekly_sales_slider.value],\n",
    "            'OrderToReceiveTime': [order_to_receive_time_slider.value],\n",
    "            'HoldingCost': [holding_cost_slider.value],\n",
    "            'DaysUntilExpiration': [days_until_expiration_slider.value]\n",
    "        })\n",
    "        \n",
    "        order_date = order_date_picker.value\n",
    "        \n",
    "        # Preprocess input data\n",
    "        X_input = scaler.transform(input_data)\n",
    "        \n",
    "        # Predict with all models\n",
    "        predicted_days_rf = rf_model.predict(X_input)[0]\n",
    "        predicted_days_xgb = xgb_model.predict(X_input)[0]\n",
    "        predicted_days_lr = lr_model.predict(X_input)[0]\n",
    "        predicted_days_lasso = lasso_model.predict(X_input)[0]\n",
    "        predicted_days_ridge = ridge_model.predict(X_input)[0]\n",
    "        predicted_days_nn = nn_model.predict(X_input)[0][0]\n",
    "        \n",
    "        # Calculate predicted optimal order dates\n",
    "        predicted_date_rf = pd.to_datetime(order_date) + pd.to_timedelta(predicted_days_rf, unit='D')\n",
    "        predicted_date_xgb = pd.to_datetime(order_date) + pd.to_timedelta(predicted_days_xgb, unit='D')\n",
    "        predicted_date_lr = pd.to_datetime(order_date) + pd.to_timedelta(predicted_days_lr, unit='D')\n",
    "        predicted_date_lasso = pd.to_datetime(order_date) + pd.to_timedelta(predicted_days_lasso, unit='D')\n",
    "        predicted_date_ridge = pd.to_datetime(order_date) + pd.to_timedelta(predicted_days_ridge, unit='D')\n",
    "        predicted_date_nn = pd.to_datetime(order_date) + pd.to_timedelta(predicted_days_nn, unit='D')\n",
    "        \n",
    "        # Create a DataFrame of results with English text\n",
    "        results_df = pd.DataFrame({\n",
    "            'Model': ['Random Forest', 'XGBoost', 'Linear Regression',\n",
    "                      'Lasso Regression', 'Ridge Regression', 'Neural Network'],\n",
    "            'Days Until Optimal Order Date': [predicted_days_rf, predicted_days_xgb,\n",
    "                                              predicted_days_lr, predicted_days_lasso,\n",
    "                                              predicted_days_ridge, predicted_days_nn],\n",
    "            'Optimal Order Date': [predicted_date_rf.date(), predicted_date_xgb.date(),\n",
    "                                   predicted_date_lr.date(), predicted_date_lasso.date(),\n",
    "                                   predicted_date_ridge.date(), predicted_date_nn.date()]\n",
    "        })\n",
    "        \n",
    "        # Display the results\n",
    "        display(results_df)\n",
    "        \n",
    "        # Plot comparison chart 1\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "        sns.barplot(x='Model', y='Days Until Optimal Order Date', data=results_df, palette='viridis', ax=ax)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "        ax.set_title('Comparison of Predicted Days Until Optimal Order by Models')\n",
    "        ax.set_xlabel('Model')\n",
    "        ax.set_ylabel('Days')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join('img', 'comparison_predicted_days_models.png'))\n",
    "        display(fig)  # Use display to show the plot\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # Plot comparison chart 2\n",
    "        fig2, ax2 = plt.subplots(figsize=(10,6))\n",
    "        sns.barplot(x='Model', y='Days Until Optimal Order Date', data=results_df, palette='magma', ax=ax2)\n",
    "        ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45)\n",
    "        ax2.set_title('Comparison of Optimal Order Dates Predicted by Models')\n",
    "        ax2.set_xlabel('Model')\n",
    "        ax2.set_ylabel('Days')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join('img', 'comparison_optimal_order_dates_models.png'))\n",
    "        display(fig2)  # Use display to show the plot\n",
    "        plt.close(fig2)\n",
    "\n",
    "# Connect the predict button to the prediction function\n",
    "predict_button.on_click(on_predict_button_clicked)\n",
    "\n",
    "# Organize widgets into a grid layout\n",
    "input_widgets = widgets.GridBox(\n",
    "    children=[\n",
    "        product_dropdown,\n",
    "        order_date_picker,\n",
    "        lead_time_slider,\n",
    "        stock_on_hand_slider,\n",
    "        capital_record_slider,\n",
    "        weekly_sales_slider,\n",
    "        order_to_receive_time_slider,\n",
    "        holding_cost_slider,\n",
    "        days_until_expiration_slider,\n",
    "        predict_button\n",
    "    ],\n",
    "    layout=widgets.Layout(\n",
    "        width='100%',\n",
    "        grid_template_columns='repeat(2, 50%)',\n",
    "        grid_template_rows='auto',\n",
    "        grid_gap='10px 10px'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the widgets\n",
    "display(widgets.VBox([\n",
    "    input_widgets,\n",
    "    output\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed103e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
